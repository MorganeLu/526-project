=================================Start loading data=============================
Subset 1: (20000, 7), (20000,)
Subset 2: (19276, 7), (19276,)
Subset 3: (18465, 7), (18465,)

 =======================================Start training LightGBM model 1=======================================
 model 1 - AUC-ROC: 0.7297 (±0.0038)

 =======================================Start training LightGBM model 2=======================================
 model 2 - AUC-ROC: 0.7316 (±0.0062)

 =======================================Start training LightGBM model 3=======================================
 model 3 - AUC-ROC: 0.7323 (±0.0070)
==========================================Calculating SHAP value for each model===============================
 SHAP summary saved to output/

LightGB final evalution
              precision    recall  f1-score   support

           0       0.73      0.91      0.81     38624
           1       0.62      0.29      0.40     18456

    accuracy                           0.71     57080
   macro avg       0.67      0.60      0.60     57080
weighted avg       0.69      0.71      0.68     57080

AUC-ROC: 0.7350787509148698


================================Start Tuning=================================

Try hyper params in round 1: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 7}
AUC-ROC: 0.7351
              precision    recall  f1-score   support

           0       0.73      0.91      0.81     38624
           1       0.62      0.29      0.40     18456

    accuracy                           0.71     57080
   macro avg       0.67      0.60      0.60     57080
weighted avg       0.69      0.71      0.68     57080


Try hyper params in round 2: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 10}
AUC-ROC: 0.7349
              precision    recall  f1-score   support

           0       0.73      0.91      0.81     38624
           1       0.61      0.29      0.40     18456

    accuracy                           0.71     57080
   macro avg       0.67      0.60      0.60     57080
weighted avg       0.69      0.71      0.68     57080


Try hyper params in round 3: {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 12}
AUC-ROC: 0.7347
              precision    recall  f1-score   support

           0       0.73      0.91      0.81     38624
           1       0.61      0.29      0.40     18456

    accuracy                           0.71     57080
   macro avg       0.67      0.60      0.60     57080
weighted avg       0.69      0.71      0.68     57080


Try hyper params in round 4: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 7, 'class_weight': 'balanced'}
AUC-ROC: 0.7349
              precision    recall  f1-score   support

           0       0.80      0.67      0.73     38624
           1       0.49      0.65      0.56     18456

    accuracy                           0.67     57080
   macro avg       0.64      0.66      0.64     57080
weighted avg       0.70      0.67      0.67     57080


All results:
AUC=0.7351 -> {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 7}
AUC=0.7349 -> {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 7, 'class_weight': 'balanced'}
AUC=0.7349 -> {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 10}
AUC=0.7347 -> {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 12}
